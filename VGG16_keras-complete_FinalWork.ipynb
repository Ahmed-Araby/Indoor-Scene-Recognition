{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEkFFZS4Xd8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the notebook and download the data\n",
        "!pip uninstall -y kaggle\n",
        "!pip install kaggle==1.5.6\n",
        "%env KAGGLE_USERNAME =ahmedaraby\n",
        "%env KAGGLE_KEY =af9b0168bb30bb0c4ec617dc6e25c015\n",
        "!kaggle competitions download -c fcis-sc-deeplearning-competition\n",
        "!unzip \"fcis-sc-deeplearning-competition.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dhrcL72LqpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports \n",
        "\n",
        "import pickle\n",
        "import os \n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import pandas as pd  \n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt  \n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# tensorflow \n",
        "import tensorflow as tf \n",
        "import tflearn\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.normalization import local_response_normalization , batch_normalization \n",
        "from tflearn.optimizers import Momentum\n",
        "from tflearn.layers.estimator import regression\n",
        "from tflearn.optimizers import SGD\n",
        "from tflearn.initializations import normal , xavier\n",
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "# keras \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Flatten\n",
        "from keras.layers import Conv2D , MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD , Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGD_rxTKeGEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### utils \n",
        "\n",
        "\n",
        "def save_into_dics(obj , name):\n",
        "    # name should include the extension\n",
        "    pickle_out = open(name , 'wb')\n",
        "    pickle.dump(obj , pickle_out)\n",
        "    pickle_out.close()\n",
        "    return\n",
        "\n",
        "\n",
        "def read_from_dics(name):\n",
        "    pickle_in = open(name , 'rb')\n",
        "    obj = pickle.load(pickle_in)\n",
        "    pickle_in.close()\n",
        "    return obj\n",
        "\n",
        "\n",
        "def shuffle(X , Y):\n",
        "    index = np.random.permutation(X.shape[0])\n",
        "\n",
        "    X = X[index]\n",
        "    Y = Y[index]\n",
        "\n",
        "    return X , Y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QdPTi4Afdye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing \n",
        "\n",
        "\n",
        "def global_mean_per_channel(X):\n",
        "\n",
        "    mean= np.mean(X , axis = (0 , 1 , 2))   # it divides by (number of examples * rows * cols )\n",
        "\n",
        "    print(\"mean of the whole data set is per channel \" , mean)\n",
        "    np.save(\"DS_local_mean.npy\" , mean)\n",
        "    return mean\n",
        "\n",
        "def normalize_min_max(img):\n",
        "    min =  np.min(img)\n",
        "    max = np.max(img)\n",
        "    img = (img - min) / (max-min)  \n",
        "    return img\n",
        "\n",
        "def resize_image(img , inputH = 256 , inputW = 256 , inputC = 3):\n",
        "    H , W , _ = img.shape\n",
        "\n",
        "    # resize the shorter side\n",
        "    # handle very small images \n",
        "    toH = inputH \n",
        "    toW = inputW\n",
        "\n",
        "    if W >= H and W>=inputH:\n",
        "        toW = W\n",
        "    if H >= W and H>=inputW:\n",
        "        toH = H\n",
        "\n",
        "    resized_img = cv2.resize(img, dsize=(toH, toW))\n",
        "    # resized_img = resized_img.reshape(toH , toW , inputC)  # big massive bug   **********************************************\n",
        "\n",
        "    # get the start/ end points of the center 256*256\n",
        "    H , W  , _ = resized_img.shape\n",
        "\n",
        "    midH = int(H/2)\n",
        "    midW = int(W/2)\n",
        "\n",
        "    # the % thing is to handle non even windows \n",
        "    startH = midH - inputH//2\n",
        "    endH = midH + inputH//2 + (inputH%2)  # excluded\n",
        "\n",
        "    startW  = midW - inputW//2\n",
        "    endW = midW + inputW//2 + (inputW%2)\n",
        "\n",
        "    # crop center inputH * inputW\n",
        "    croped_img = resized_img[startH:endH , startW:endW , :]\n",
        "\n",
        "    H , W , C = croped_img.shape\n",
        "    assert (H==inputH and W == inputW and C== inputC)\n",
        "    return croped_img\n",
        "\n",
        "\n",
        "def preprocessing(img  , inputH=256 , inputW=256 , inputC=3):\n",
        "    img = resize_image(img , inputH , inputW , inputC)\n",
        "    return img\n",
        "\n",
        "def dataset_preprocessing(X , mode=1):\n",
        "\n",
        "    # centering then normalization [0 , 1]\n",
        "    if mode==1:\n",
        "        print(\"centering then normalization \") \n",
        "        #mean = global_mean_per_channel(X)\n",
        "        mean = np.load(\"DS_local_mean.npy\")\n",
        "        #mean = np.array(mean).reshape(1, 1, 1, 3)  \n",
        "        X = X - mean\n",
        "\n",
        "        # normalization\n",
        "        for i in range(0 , X.shape[0], 1):\n",
        "            X[i] = normalize_min_max(X[i])\n",
        "\n",
        "\n",
        "    #[ TO DO ]\n",
        "    # normalization then centering\n",
        "    else :\n",
        "      assert(\"not implemented yet\")\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSIj2-GEfn1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### agumentation \n",
        "import imutils  # for rotating without cropping the edges\n",
        "# for preprocessing  \n",
        "inputH = 256\n",
        "inputW = 256\n",
        "inputC = 3\n",
        "\n",
        "# to be feed for the CNN\n",
        "CNNH = 227\n",
        "CNNW = 227\n",
        "CNNC = 3\n",
        "\n",
        "mode = -1 # -1 BGR , 0  gray\n",
        "\n",
        "def horizontal_reflication_img(img , CNNH=227 , CNNW=227 , CNNC=3):\n",
        "    H, W, C = img.shape\n",
        "    assert (H == CNNH and W == CNNW and C == CNNC)\n",
        "    hflip = cv2.flip(img , 1)\n",
        "    return hflip\n",
        "\n",
        "def extract_random_portion(img , CNNH = 227, CNNW = 227, CNNC = 3):\n",
        "    H , W , C = img.shape\n",
        "    assert (H==inputH and W==inputW and C==inputC)\n",
        "\n",
        "    startH = np.random.randint(low=0 , high=H - CNNH)\n",
        "    startW = np.random.randint(low=0 , high=W - CNNW)\n",
        "    endH = startH + CNNH\n",
        "    endW = startW + CNNW\n",
        "\n",
        "    assert (endH <= H and endW <=W)\n",
        "    ex_img = img[startH:endH , startW:endW , :]\n",
        "    H , W , C = ex_img.shape\n",
        "    assert (H == CNNH and W == CNNW and C == CNNC)\n",
        "    return ex_img\n",
        "\n",
        "def rotate_img_keep(img):\n",
        "    # images get reshaped\n",
        "    angle = np.random.random_integers(low=-45 , high=45)\n",
        "    rot_img = imutils.rotate_bound(img , angle)\n",
        "    return rot_img\n",
        "\n",
        "def add_gauusian_noise(img):\n",
        "    blured_img = cv2.GaussianBlur(img , (7 , 7) , 1.5)\n",
        "    return blured_img\n",
        "\n",
        "def add_salt_peper_noise(img):\n",
        "    salty_img = np.copy(img)\n",
        "    for i in range(0 , img.shape[0]):\n",
        "        for j in range(0 ,  img.shape[1]):\n",
        "            rand = np.random.random_sample()\n",
        "            if rand <= 0.03:\n",
        "                salty_img[i , j , :] = 0\n",
        "            elif rand <= 0.07:\n",
        "                salty_img[i, j, :] = 255\n",
        "    return salty_img\n",
        "\n",
        "def Agumentation(img, CNNH=227 , CNNW=227 , CNNC=3):\n",
        "    ex_img = extract_random_portion(img , CNNH , CNNW , CNNC)\n",
        "    Hfliped_img = horizontal_reflication_img(ex_img , CNNH , CNNW , CNNC) \n",
        "\n",
        "    rotate_img = rotate_img_keep(ex_img)   #rotate change the size of the image\n",
        "    gauss_img = add_gauusian_noise(ex_img)\n",
        "    #salty_img = add_salt_peper_noise(ex_img)\n",
        "    # make sure they are 227\n",
        "    rotate_img = cv2.resize(img, dsize=(227, 227))\n",
        "    # string is to make the image unique form the original\n",
        "    img_l = [ ( ex_img  , \"227\"), ( Hfliped_img , \"flip\"), (rotate_img , \"rotate\") , (gauss_img , \"gauss\") ] #, (salty_img , \"salty\")]\n",
        "    # string is to make the image unique form the original\n",
        "\n",
        "    #img_l = [ ( ex_img  , str(CNNH)), ( Hfliped_img , \"flip\")]\n",
        "    return img_l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaNZAChnfwHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate train and validation data \n",
        "\n",
        "# labels as in kaggle but 0 - based \n",
        "label_dict = {'airport_inside': 0, 'bakery': 1, 'bedroom': 2, 'greenhouse': 3,\n",
        "              'gym': 4, 'kitchen': 5, 'operating_room': 6, 'poolinside': 7,\n",
        "              'restaurant': 8, 'toystore': 9}\n",
        "\n",
        "# for preprocessing  \n",
        "inputH = 256\n",
        "inputW = 256\n",
        "inputC = 3\n",
        "\n",
        "# to be feed for the CNN\n",
        "CNNH = 227\n",
        "CNNW = 227\n",
        "CNNC = 3\n",
        "\n",
        "mode = -1 # -1 BGR , 0  gray\n",
        "\n",
        "# image.shape (height ,  width , channels )\n",
        "\n",
        "SLASH = '/'\n",
        "corrupted = ['indooPool_Inside_gif.jpg']\n",
        "\n",
        "def get_path_list(path):\n",
        "    path_list = listdir(path)\n",
        "    return path_list\n",
        "\n",
        "def check_image(img):\n",
        "    if mode==-1 and ( len(img.shape)!=3 or img.shape[2] != 3): # img.shape[0] < 256 or img.shape[1] < 256 or (we will do upsampling)\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "def split_data(path):\n",
        "    # file with 10 folders\n",
        "    file_list =  get_path_list(path)\n",
        "\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    X_valid = []\n",
        "    Y_valid = []\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(0 , len(file_list) , 1):\n",
        "        # specific file of the 10\n",
        "        class_path = path + SLASH + file_list[i]\n",
        "\n",
        "        # images paths in 1 folder of the 10 folders\n",
        "        class_path_list = get_path_list(class_path)\n",
        "\n",
        "        # iterate throw the images of 1 class\n",
        "        tl_img   =   []\n",
        "        tl_label =   []\n",
        "        end = len(class_path_list) - int(0.1*len(class_path_list))\n",
        "        for j in range(0 , len(class_path_list) , 1):\n",
        "            final_path = class_path + SLASH + class_path_list[j]\n",
        "\n",
        "            # corrupted images\n",
        "            if class_path_list[j] in corrupted:\n",
        "                continue\n",
        "\n",
        "            img = cv2.imread(final_path , mode) \n",
        "\n",
        "            if check_image(img)==0:\n",
        "                continue\n",
        "\n",
        "            print(\"final_path : \"  , final_path)\n",
        "            #print(\"class name \" , file_list[i])\n",
        "\n",
        "            img = img[: , : , (2 , 1 , 0)]    # converting the image to be RGB \n",
        "            cnt+=1\n",
        "            # apply preprocessing and agumentation\n",
        "            img = preprocessing(img , inputH , inputW , inputC)\n",
        "            img_l = Agumentation(img , CNNH , CNNW , CNNC)  \n",
        "\n",
        "            for q in range(0 , len(img_l)):\n",
        "                timg = img_l[q][0]\n",
        "                tl_img.append(timg)\n",
        "                tl_label.append(label_dict[file_list[i]])\n",
        "\n",
        "        # balance one class beteen train and valid   data ...\n",
        "        index = np.random.permutation(len(tl_img))\n",
        "        end = len(tl_img) - int(0.1 * len(tl_img))\n",
        "\n",
        "        for q in range(0 , len(index)):\n",
        "          ind = index[q]\n",
        "          if q < end:            \n",
        "            X_train.append(tl_img[ind])\n",
        "            Y_train.append(tl_label[ind])\n",
        "          else:\n",
        "            X_valid.append(tl_img[ind])\n",
        "            Y_valid.append(tl_label[ind])\n",
        "\n",
        "    \n",
        "    # reshape the data\n",
        "    X_train = np.array(X_train).reshape(-1 , CNNH , CNNW , CNNC)\n",
        "    Y_train = np.array(Y_train).reshape(-1, 1)\n",
        "\n",
        "    X_valid = np.array(X_valid).reshape(-1, CNNH, CNNW, CNNC)\n",
        "    Y_valid = np.array(Y_valid).reshape(-1, 1)\n",
        "    \n",
        "    # final preprocessing \n",
        "    #X_train = dataset_preprocessing(X_train , 1)\n",
        "    #  *************************\n",
        "\n",
        "    # shuffle \n",
        "    X_train , Y_train = shuffle(X_train ,Y_train)\n",
        "    \n",
        "    print(\"count \" , cnt)\n",
        "    print(\"train data shape \" , X_train.shape , Y_train.shape)\n",
        "    print(\"valid data shape \" , X_valid.shape , Y_valid.shape)\n",
        "    \n",
        "\n",
        "\n",
        "    # cast \n",
        "    X_train = X_train.astype(np.float32)\n",
        "    \n",
        "\n",
        "    # save the data into the disc\n",
        "    np.save(\"X_train.npy\", X_train)\n",
        "    np.save(\"Y_train.npy\", Y_train)\n",
        "\n",
        "    np.save(\"X_valid.npy\" , X_valid)\n",
        "    np.save(\"Y_valid.npy\" , Y_valid)\n",
        "\n",
        "    return \n",
        "    \n",
        "\"\"\"\n",
        "def save_to_csv(image_path, labelid,name='train.csv'):\n",
        "    tmp_dict = {\"image_path\":image_path , \"labelid\":labelid}\n",
        "    Data = pd.DataFrame(tmp_dict)\n",
        "    Data.to_csv(name)\n",
        "    return Data\n",
        "\"\"\"\n",
        "\n",
        "print(\"start\")\n",
        "split_data(\"train/train\")\n",
        "print(\"end\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYCM3lLxpab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def VGG_16(lmda=0.005 , drop=0.7):\n",
        "\n",
        "    # winit = RandomNormal(mean=0.0 , stddev=0.01)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # first block of conv layers\n",
        "    model.add(Conv2D(64 , (3 , 3) , padding='same' , activation='relu' , input_shape=(227 , 227 , 3) , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(64 , (3 , 3) , strides=(1 , 1) , padding='same'  , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # second block of conv layers\n",
        "    model.add(Conv2D(128 , (3 , 3) , padding='same' , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # third block of conv layers\n",
        "    model.add(Conv2D(256 , (3 , 3) , padding='same' , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(256 , (3 , 3) , padding='same' , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # forth block\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # fifth block\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # flatten\n",
        "    model.add(Flatten())  # channel last\n",
        "\n",
        "    # fully connected layers\n",
        "    model.add(Dense(4096 , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Dropout(rate=drop))\n",
        "\n",
        "    model.add(Dense(4096, activation='relu' , kernel_regularizer=l2(lmda)  ))\n",
        "    model.add(Dropout(rate=drop))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax',  kernel_regularizer=l2(lmda)  ))\n",
        "\n",
        "    return model\n",
        "\n",
        "def freeze_layers(model):\n",
        "    print(\"freze conv layers\")\n",
        "    index = [ 0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 16]\n",
        "    for i in range(0 , len(index)):\n",
        "        model.layers[index[i]].trainable=False   # bug *****************************\n",
        "\n",
        "    print(\"freze FC layers\")\n",
        "    index = [19, 21, 23]\n",
        "    for i in range(0, len(index)-2):\n",
        "      model.layers[index[i]].trainable = False    # bug ********************\n",
        "      \n",
        "    return model\n",
        "\n",
        "# load trianable parameters \n",
        "\n",
        "def set_conv_weights(model, index , path=\"/content/drive/My\"+\" \"+\"Drive/vgg16_weights.npz\"):\n",
        "    print(\"initialize  some conv layers \")\n",
        "    W = np.load(path)\n",
        "    block = 1\n",
        "    layer = 1\n",
        "\n",
        "    for i in range(0 , len(index)):\n",
        "        # reset the pattern , by detecting\n",
        "        # the max pool layer and flatten layer\n",
        "        if i!=0 and index[i]-index[i-1]>1:\n",
        "            block += 1\n",
        "            layer = 1\n",
        "\n",
        "        weight = \"conv\" + str(block) + '_' + str(layer) + '_' + 'W'\n",
        "        bias = \"conv\" + str(block) + '_' + str(layer) + '_' + 'b'\n",
        "\n",
        "        # make sure that we are the right match\n",
        "        X , Y =model.layers[index[i]].get_weights()\n",
        "        X = X.shape\n",
        "        Y = Y.shape\n",
        "        XX = W[weight].shape\n",
        "        YY = W[bias].shape\n",
        "        #print(X , XX , Y , YY)\n",
        "        assert(X == XX and Y == YY)\n",
        "\n",
        "        #print(\"for debugining \" , index[i] , weight , bias)\n",
        "        model.layers[ index[i] ].set_weights([W[weight] , W[bias]])\n",
        "        layer +=1\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def set_fc_weights(model , index, path=\"/content/drive/My\"+\" \"+\"Drive/vgg16_weights.npz\"):\n",
        "    print(\" initialize some FC layers \")\n",
        "    W = np.load(path)\n",
        "\n",
        "    layer = 6\n",
        "    for i in range(0 , len(index)-1): # leave the output layer\n",
        "        model.layers[index[i]].set_weights([W[\"fc\"+str(layer)+\"_W\"] , W[\"fc\"+str(layer)+\"_b\"]])\n",
        "        layer += 1\n",
        "\n",
        "    return model\n",
        "\n",
        "def set_weights(model):\n",
        "    # I think we don't need to return the model back as we edit what in it not assign to it \n",
        "    print(\"in set weights\")\n",
        "    # conv layers\n",
        "    index = [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15 , 16]\n",
        "    model = set_conv_weights(model, index)\n",
        "\n",
        "    # fulle connected layers\n",
        "    index = [19, 21, 23]\n",
        "    model = set_fc_weights(model , index)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23MLk3YChNrD",
        "colab_type": "code",
        "outputId": "f51ad944-422f-4baf-85f6-ec16d9b48422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# VGG-16   keras from scratch\n",
        "\n",
        "print(\"start\")\n",
        "X_valid = np.load(\"X_valid.npy\")\n",
        "Y_valid = np.load(\"Y_valid.npy\")\n",
        "\n",
        "X_train = np.load('X_train.npy')\n",
        "Y_train = np.load('Y_train.npy')\n",
        "\n",
        "sess = tf.Session()\n",
        "Y_train = sess.run(tf.one_hot(Y_train , depth=10))\n",
        "Y_valid = sess.run(tf.one_hot(Y_valid , depth=10))\n",
        "sess.close()\n",
        "\n",
        "Y_train = np.squeeze(Y_train)\n",
        "Y_valid = np.squeeze(Y_valid)\n",
        "\n",
        "print(X_train.shape , Y_train.shape, type(X_train[0][0][0][0]) , X_train[0][0][0])\n",
        "print(X_valid.shape , Y_valid.shape,  type(X_valid[0][0][0][0]),  X_valid[0][0][0])\n",
        "\n",
        "# model = VGG_16()\n",
        "model = load_model('full_model_19.h5')\n",
        "\n",
        "model = freeze_layers(model)\n",
        "\n",
        "# model = set_weights(model)\n",
        "\n",
        "sgd = SGD(lr=0.001 , momentum=0.9)\n",
        "\n",
        "# opt = Adam(lr=0.01)\n",
        "model.compile(optimizer=sgd , loss=\"categorical_crossentropy\" , metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "img1 = X_train[14]\n",
        "#img2 = X_valid[31]\n",
        "\n",
        "plt.imshow(img1)\n",
        "#plt.imshow(img2)\n",
        "\n",
        "\n",
        "# callbacks \n",
        "\n",
        "best_val_acc = ModelCheckpoint('bestmodel.h5' , monitor='val_acc' , save_best_only=True , mode='max')\n",
        "\n",
        "model.fit(x=X_train , y=Y_train , batch_size=256 , epochs=50 ,callbacks=[best_val_acc], validation_data=(X_valid , Y_valid))\n",
        "\n",
        "print(\"save weights\")\n",
        "model.save_weights('full_weights_19.h5')\n",
        "\n",
        "print(\"save model\")\n",
        "model.save('full_model_19.h5')\n",
        "print(\"end\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "(11269, 227, 227, 3) (11269, 10) <class 'numpy.float32'> [0.50387   0.5412651 0.5861068]\n",
            "(1247, 227, 227, 3) (1247, 10) <class 'numpy.float32'> [0.644804  0.6981307 0.7554192]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "freze conv layers\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 227, 227, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 227, 227, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 113, 113, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 113, 113, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 119,586,826\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 11269 samples, validate on 1247 samples\n",
            "Epoch 1/50\n",
            "11269/11269 [==============================] - 42s 4ms/step - loss: 11.1278 - acc: 0.8166 - val_loss: 11.2048 - val_acc: 0.7851\n",
            "Epoch 2/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.1962 - acc: 0.7822 - val_loss: 11.1363 - val_acc: 0.7923\n",
            "Epoch 3/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.1268 - acc: 0.8002 - val_loss: 11.1516 - val_acc: 0.7923\n",
            "Epoch 4/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.1987 - acc: 0.7643 - val_loss: 11.1579 - val_acc: 0.7787\n",
            "Epoch 5/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.1495 - acc: 0.7718 - val_loss: 11.0731 - val_acc: 0.7859\n",
            "Epoch 6/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.1015 - acc: 0.7799 - val_loss: 11.1022 - val_acc: 0.7706\n",
            "Epoch 7/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.0546 - acc: 0.7934 - val_loss: 11.1003 - val_acc: 0.7739\n",
            "Epoch 8/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.1285 - acc: 0.7567 - val_loss: 11.0831 - val_acc: 0.7698\n",
            "Epoch 9/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.0714 - acc: 0.7710 - val_loss: 10.9977 - val_acc: 0.7875\n",
            "Epoch 10/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.0567 - acc: 0.7718 - val_loss: 11.0057 - val_acc: 0.7787\n",
            "Epoch 11/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.0322 - acc: 0.7668 - val_loss: 10.9882 - val_acc: 0.7835\n",
            "Epoch 12/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.9539 - acc: 0.7947 - val_loss: 11.1168 - val_acc: 0.7121\n",
            "Epoch 13/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.0509 - acc: 0.7456 - val_loss: 10.9871 - val_acc: 0.7634\n",
            "Epoch 14/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.9697 - acc: 0.7665 - val_loss: 11.2679 - val_acc: 0.6455\n",
            "Epoch 15/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 11.0856 - acc: 0.7159 - val_loss: 10.8957 - val_acc: 0.7835\n",
            "Epoch 16/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.8785 - acc: 0.7880 - val_loss: 10.8873 - val_acc: 0.7907\n",
            "Epoch 17/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.9320 - acc: 0.7640 - val_loss: 10.8762 - val_acc: 0.7955\n",
            "Epoch 18/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.9022 - acc: 0.7679 - val_loss: 10.8407 - val_acc: 0.7939\n",
            "Epoch 19/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.8317 - acc: 0.7892 - val_loss: 10.7912 - val_acc: 0.7979\n",
            "Epoch 20/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.7597 - acc: 0.8100 - val_loss: 10.7596 - val_acc: 0.8123\n",
            "Epoch 21/50\n",
            "11269/11269 [==============================] - 33s 3ms/step - loss: 10.7424 - acc: 0.8073 - val_loss: 10.7459 - val_acc: 0.7971\n",
            "Epoch 22/50\n",
            "11008/11269 [============================>.] - ETA: 0s - loss: 10.7416 - acc: 0.7986"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TC5zYUag3H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sw6Ex6hqPXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict \n",
        "def get_5_portions(img , inputH=227 , inputW=227):\n",
        "    H , W , _ = img.shape\n",
        "\n",
        "    # first portion\n",
        "    img_l = []\n",
        "    img_l.append(img[0:227 , 0:227 , :])\n",
        "\n",
        "    # second portion\n",
        "    img_l.append(img[0:227 , W-228:W-1 , :])  # order of the second index matters !!!\n",
        "\n",
        "    # third portion\n",
        "    img_l.append(img[H-228:H-1 , 0:227 , :])\n",
        "\n",
        "    # 4th portion\n",
        "    img_l.append(img[H-228:H-1 , W-228:W-1 , :])\n",
        "\n",
        "    # get center portion\n",
        "    midH = H//2\n",
        "    midW = W//2\n",
        "\n",
        "    startH = midH - inputH//2\n",
        "    endH = midH + inputH//2 + (inputH%2)\n",
        "\n",
        "    startW = midW - inputW//2\n",
        "    endW = midW + inputW // 2 + (inputW % 2)\n",
        "    img_l.append(img[startH:endH , startW:endW , :])\n",
        "\n",
        "    # check\n",
        "    \"\"\"\n",
        "    index = 0\n",
        "    for timg in img_l:\n",
        "        H , W , C = timg.shape\n",
        "        # print(index)  # for debuging\n",
        "        assert(H==inputH and W==inputW and C==3)\n",
        "        index +=1\n",
        "    \"\"\"\n",
        "    return img_l\n",
        "\n",
        "def predict(X):\n",
        "    labels = model.predict(X)\n",
        "    labels = np.squeeze(np.argmax(labels , axis=1))\n",
        "\n",
        "    labels = np.bincount(labels)\n",
        "    labels= np.argmax(labels)\n",
        "    return labels\n",
        "\n",
        "def test(path):\n",
        "    img_name  =  []\n",
        "    img_label =  []\n",
        "\n",
        "    mean = np.load('DS_local_mean.npy')\n",
        "    mean = mean.reshape(1 , 1 , 3)\n",
        "\n",
        "    file = listdir(path)\n",
        "    for name in file:\n",
        "        final_path = path + \"/\" + name #os.path.join(path , name)\n",
        "        img = cv2.imread(final_path , -1)\n",
        "\n",
        "        ###################################################################################\n",
        "\n",
        "        # bad image\n",
        "        if name=='1412_mb_file_0a8c5_gif.jpg':   # gif image\n",
        "            print(\"bad image \")\n",
        "            img_name.append(name)\n",
        "            img_label.append(5)  # grean house \n",
        "            continue\n",
        "        if name==\"operating_room_07_06_altavista.jpg\":  # gray scale img and my model take only RGB\n",
        "            print(\"bad image \")\n",
        "            img_name.append(name)\n",
        "            img_label.append(3) # operating room \n",
        "            continue\n",
        "\n",
        "        ####################################################################################\n",
        "\n",
        "        # put the image in the same conditions of training\n",
        "        print(name)\n",
        "        # RGB\n",
        "        img = img[: , : , (2 , 1 , 0)]\n",
        "\n",
        "        # resize into 256 * 256\n",
        "        img = preprocessing(img)\n",
        "\n",
        "        # subtract the mean\n",
        "        #img = img - mean\n",
        "\n",
        "        # normalize the image\n",
        "        #img = normalize_min_max(img)\n",
        "\n",
        "        # this procedure is from alexnet - image net paper\n",
        "        # generate all the agumented imgs and vote for label\n",
        "        img_l = []\n",
        "        img_l = get_5_portions(img) # 227*227\n",
        "        #get the flips of each image\n",
        "        sz = len(img_l)\n",
        "        for i in range(0 , sz):\n",
        "            fimg= horizontal_reflication_img(img_l[i])\n",
        "            img_l.append(fimg)\n",
        "        img_l = np.array(img_l).reshape(-1 , 227 , 227 , 3)\n",
        "        label = predict(img_l)\n",
        "\n",
        "        # build the file\n",
        "        img_name.append(name)\n",
        "        img_label.append(label+1)\n",
        "    return img_name , img_label\n",
        "\n",
        "def save_to_csv_file(names , labels):\n",
        "  Data = {\"id\":names , \"lable\":labels}\n",
        "  Data = pd.DataFrame(Data)\n",
        "  Data.to_csv(\"mysubmit.csv\")\n",
        "  return Data\n",
        "\n",
        "weight_path = \"/content/drive/My\"+\" \"+\"Drive\"\"/bestmodel3-96.h5\"\n",
        "\n",
        "print(\"start\")\n",
        "model = load_model(\"bestmodel.h5\") #VGG_16()\n",
        "#model.load_weights(weight_path)\n",
        "names , labels = test('/content/test/test')\n",
        "print(\"\\n\\n\")\n",
        "print(names)\n",
        "print(labels)\n",
        "print(\"end\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMZyWSF73nnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"start\")\n",
        "# load data\n",
        "X = np.load('/content/X.npy')\n",
        "Y = np.load('/content/Y.npy')\n",
        "sess = tf.Session()\n",
        "Y = sess.run(tf.one_hot(Y , depth=10))\n",
        "sess.close()\n",
        "Y = np.squeeze(Y)\n",
        "\n",
        "model = load_model(\"/content/drive/My\"+\" \"+\"Drive/bestmodel3-96.h5\")\n",
        "#print(model.summary())\n",
        "#pred = model.predict(X)\n",
        "print(model.evaluate(X , Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg6sv1OWWeK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 2. Save Keras Model or weights on google drive\n",
        "\n",
        "# create on Colab directory\n",
        "\n",
        "model_file = drive.CreateFile({'title' : 'bestmodel_87.h5'})\n",
        "model_file.SetContentFile('bestmodel_87.h5')\n",
        "model_file.Upload()\n",
        "\n",
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}