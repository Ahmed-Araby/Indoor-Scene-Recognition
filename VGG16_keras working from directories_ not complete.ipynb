{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16-keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEkFFZS4Xd8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the notebook and download the data\n",
        "!pip uninstall -y kaggle\n",
        "!pip install kaggle==1.5.6\n",
        "%env KAGGLE_USERNAME =ahmedaraby\n",
        "%env KAGGLE_KEY =af9b0168bb30bb0c4ec617dc6e25c015\n",
        "!kaggle competitions download -c fcis-sc-deeplearning-competition\n",
        "!unzip \"fcis-sc-deeplearning-competition.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dhrcL72LqpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "813ccdf5-d8a5-4232-a201-c33909182dbd"
      },
      "source": [
        "# imports \n",
        "\n",
        "import pickle\n",
        "import os \n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import pandas as pd  \n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt  \n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# tensorflow \n",
        "import tensorflow as tf \n",
        "import tflearn\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.normalization import local_response_normalization , batch_normalization \n",
        "from tflearn.optimizers import Momentum\n",
        "from tflearn.layers.estimator import regression\n",
        "from tflearn.optimizers import SGD\n",
        "from tflearn.initializations import normal , xavier\n",
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "# keras \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Flatten\n",
        "from keras.layers import Conv2D , MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD , Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGD_rxTKeGEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### utils \n",
        "\n",
        "\n",
        "def save_into_dics(obj , name):\n",
        "    # name should include the extension\n",
        "    pickle_out = open(name , 'wb')\n",
        "    pickle.dump(obj , pickle_out)\n",
        "    pickle_out.close()\n",
        "    return\n",
        "\n",
        "\n",
        "def read_from_dics(name):\n",
        "    pickle_in = open(name , 'rb')\n",
        "    obj = pickle.load(pickle_in)\n",
        "    pickle_in.close()\n",
        "    return obj\n",
        "\n",
        "\n",
        "def shuffle(X , Y):\n",
        "    index = np.random.permutation(len(X))\n",
        "\n",
        "    X = X[index]\n",
        "    Y = Y[index]\n",
        "\n",
        "    return X , Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmBGgfkdcn7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing \n",
        "def subtract_mean(img):\n",
        "    mean = [132.46343732, 118.07325045, 102.6140029]\n",
        "    img = img - mean \n",
        "    img = normalize_min_max(img)\n",
        "    return img\n",
        "\n",
        "def normalize_min_max(img):\n",
        "    min =  np.min(img)\n",
        "    max = np.max(img)\n",
        "    img = (img - min) / (max-min)  \n",
        "    return img\n",
        "\n",
        "def resize_image(img , inputH = 256 , inputW = 256 , inputC = 3):\n",
        "    H , W , _ = img.shape\n",
        "\n",
        "    # resize the shorter side\n",
        "    # handle very small images \n",
        "    toH = inputH \n",
        "    toW = inputW\n",
        "\n",
        "    if W >= H and W>=inputH:\n",
        "        toW = W\n",
        "    if H >= W and H>=inputW:\n",
        "        toH = H\n",
        "\n",
        "    resized_img = cv2.resize(img, dsize=(toH, toW))\n",
        "    # resized_img = resized_img.reshape(toH , toW , inputC)  # big massive bug   **********************************************\n",
        "\n",
        "    # get the start/ end points of the center 256*256\n",
        "    H , W  , _ = resized_img.shape\n",
        "\n",
        "    midH = int(H/2)\n",
        "    midW = int(W/2)\n",
        "\n",
        "    # the % thing is to handle non even windows \n",
        "    startH = midH - inputH//2\n",
        "    endH = midH + inputH//2 + (inputH%2)  # excluded\n",
        "\n",
        "    startW  = midW - inputW//2\n",
        "    endW = midW + inputW//2 + (inputW%2)\n",
        "\n",
        "    # crop center inputH * inputW\n",
        "    croped_img = resized_img[startH:endH , startW:endW , :]\n",
        "\n",
        "    H , W , C = croped_img.shape\n",
        "    assert (H==inputH and W == inputW and C== inputC)\n",
        "    return croped_img\n",
        "\n",
        "\n",
        "def preprocessing(img  , inputH=256 , inputW=256 , inputC=3):\n",
        "    img = resize_image(img , inputH , inputW , inputC)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QdPTi4Afdye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### agumentation \n",
        "import imutils  # for rotating without cropping the edges\n",
        "# for preprocessing  \n",
        "inputH = 256\n",
        "inputW = 256\n",
        "inputC = 3\n",
        "\n",
        "# to be feed for the CNN\n",
        "CNNH = 227\n",
        "CNNW = 227\n",
        "CNNC = 3\n",
        "\n",
        "mode = -1 # -1 BGR , 0  gray\n",
        "\n",
        "def horizontal_reflication_img(img , CNNH=227 , CNNW=227 , CNNC=3):\n",
        "    H, W, C = img.shape\n",
        "    assert (H == CNNH and W == CNNW and C == CNNC)\n",
        "    hflip = cv2.flip(img , 1)\n",
        "    return hflip\n",
        "\n",
        "def extract_random_portion(img , CNNH = 227, CNNW = 227, CNNC = 3):\n",
        "    H , W , C = img.shape\n",
        "    assert (H==inputH and W==inputW and C==inputC)\n",
        "\n",
        "    startH = np.random.randint(low=0 , high=H - CNNH)\n",
        "    startW = np.random.randint(low=0 , high=W - CNNW)\n",
        "    endH = startH + CNNH\n",
        "    endW = startW + CNNW\n",
        "\n",
        "    assert (endH <= H and endW <=W)\n",
        "    ex_img = img[startH:endH , startW:endW , :]\n",
        "    H , W , C = ex_img.shape\n",
        "    assert (H == CNNH and W == CNNW and C == CNNC)\n",
        "    return ex_img\n",
        "\n",
        "def rotate_img_keep(img):\n",
        "    # images get reshaped\n",
        "    angle = np.random.random_integers(low=-5 , high=5)\n",
        "    rot_img = imutils.rotate_bound(img , angle)\n",
        "    # rot_img = imutils.rotate(img , angle)\n",
        "    return rot_img\n",
        "\n",
        "def add_gauusian_noise(img):\n",
        "    blured_img = cv2.GaussianBlur(img , (7 , 7) , 1)\n",
        "    return blured_img\n",
        "\n",
        "def add_salt_peper_noise(img):\n",
        "    salty_img = np.copy(img)\n",
        "    for i in range(0 , img.shape[0]):\n",
        "        for j in range(0 ,  img.shape[1]):\n",
        "            rand = np.random.random_sample()\n",
        "            if rand <= 0.005:\n",
        "                salty_img[i , j , :] = 0\n",
        "            elif rand <= 0.009:\n",
        "                salty_img[i, j, :] = 255\n",
        "    return salty_img\n",
        "\n",
        "def Agumentation(img,num, CNNH=227 , CNNW=227 , CNNC=3):\n",
        "    ex_img = extract_random_portion(img , CNNH , CNNW , CNNC)\n",
        "    Hfliped_img = horizontal_reflication_img(ex_img , CNNH , CNNW , CNNC) \n",
        "\n",
        "    #rotate_img = rotate_img_keep(ex_img)   #rotate change the size of the image\n",
        "    #gauss_img = add_gauusian_noise(ex_img)\n",
        "    #salty_img = add_salt_peper_noise(ex_img)\n",
        "    # make sure they are 227\n",
        "    # rotate_img = cv2.resize(img, dsize=(CNNH, CNNW))\n",
        "    # string is to make the image unique form the original\n",
        "    img_l = [ ( ex_img  , str(CNNH)+str(num)+\".jpg\"), ( Hfliped_img , \"flip\"+str(num)+\".jpg\")]\n",
        "             #,(gauss_img , \"gauss\"+str(num)+\".jpg\") ]\n",
        "             #, (salty_img , \"salty\"+str(num)+\".jpg\")] \n",
        "             #(rotate_img , \"rotate\"+str(num)+\".jpg\") \n",
        "\n",
        "    # string is to make the image unique form the original\n",
        "    #img_l = [ ( ex_img  , str(CNNH)), ( Hfliped_img , \"flip\")]\n",
        "    return img_l\n",
        "    \n",
        "def combine_agumentation(img):\n",
        "    # **** now we are officially dublicated *** to balance the classes variations \n",
        "    #w = np.random.random()\n",
        "    #img = rotate_img_keep(img)   #rotate change the size of the image\n",
        "    \n",
        "    #if w < 0.2:\n",
        "        #img = add_gauusian_noise(img)\n",
        "    #if w < 0.5:\n",
        "      #img = add_salt_peper_noise(img)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSIj2-GEfn1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate train and validation data \n",
        "\n",
        "# labels as in kaggle but 0 - based \n",
        "label_dict = {'airport_inside': 0, 'bakery': 1, 'bedroom': 2, 'greenhouse': 3,\n",
        "              'gym': 4, 'kitchen': 5, 'operating_room': 6, 'poolinside': 7,\n",
        "              'restaurant': 8, 'toystore': 9}\n",
        "\n",
        "# for preprocessing  \n",
        "inputH = 256\n",
        "inputW = 256\n",
        "inputC = 3\n",
        "\n",
        "# to be feed for the CNN\n",
        "CNNH = 227\n",
        "CNNW = 227\n",
        "CNNC = 3\n",
        "\n",
        "mode = -1 # -1 BGR , 0  gray\n",
        "\n",
        "# image.shape (height ,  width , channels )\n",
        "\n",
        "corrupted = ['indooPool_Inside_gif.jpg']\n",
        "\n",
        "def check_image(img):\n",
        "    if mode==-1 and ( len(img.shape)!=3 or img.shape[2] != 3): # img.shape[0] < 256 or img.shape[1] < 256 or (we will do upsampling)\n",
        "        return 0\n",
        "    return 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaNZAChnfwHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path = '/content/train/train'\n",
        "save_path_train = '/content/my_train/train'\n",
        "save_path_valid = '/content/my_valid/valid'\n",
        "main_file = listdir(path)\n",
        "os.mkdir(\"/content/my_valid\")\n",
        "os.mkdir(\"/content/my_valid/valid\")\n",
        "\n",
        "os.mkdir(\"/content/my_train\")\n",
        "os.mkdir(\"/content/my_train/train\")\n",
        "for class_name in main_file:\n",
        "  new_path_train = os.path.join(save_path_train , class_name)\n",
        "  new_path_valid = os.path.join(save_path_valid , class_name)\n",
        "  os.mkdir(new_path_train)\n",
        "  os.mkdir(new_path_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYCM3lLxpab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making Directories \n",
        "\n",
        "Data_path = '/content/train/train'\n",
        "save_train_path = '/content/my_train/train'\n",
        "save_valid_path = '/content/my_valid/valid'\n",
        "save_test_path = '/content/my_test/test'\n",
        "\n",
        "MAX = 600  # max number of images in each class \n",
        "num = 0\n",
        "def build_Data_Set():\n",
        "    global num\n",
        "    train_file = os.listdir(Data_path)\n",
        "\n",
        "    for class_name in train_file:\n",
        "        class_file_path = os.path.join(Data_path , class_name)\n",
        "        class_file = listdir(class_file_path)\n",
        "\n",
        "        # ***** handle un blanced classes number ******\n",
        "        class_length = len(class_file)\n",
        "        cnt = 0\n",
        "        ACG = MAX - class_length\n",
        "        tl_img = []\n",
        "        tl_label = []  # we don't need it \n",
        "        for img_name in class_file:\n",
        "            img_path = os.path.join(class_file_path , img_name)\n",
        "\n",
        "            # corrupted images\n",
        "            if img_name in corrupted:\n",
        "                continue\n",
        "            img = cv2.imread(img_path, mode) \n",
        "            # check img \n",
        "            if check_image(img)==0:\n",
        "                continue\n",
        "\n",
        "            print(\"final path :\" , img_path)\n",
        "            # apply preprocessing   (256*256 crop)\n",
        "            img = preprocessing(img , inputH , inputW , inputC)\n",
        "\n",
        "            # apply agumentation\n",
        "            img_l = Agumentation(img ,num, CNNH , CNNW , CNNC)\n",
        "            num +=1\n",
        "            # temp save into list \n",
        "            \n",
        "            for q in range(0 , len(img_l) , 1):\n",
        "              if q!=0 and cnt >= ACG:\n",
        "                break\n",
        "              tl_img.append(img_l[q])\n",
        "              tl_label.append(label_dict[class_name]) # *****\n",
        "              \n",
        "            if cnt < ACG:\n",
        "                cnt += ( len(img_l)-1 )\n",
        "          \n",
        "\n",
        "        print(\"length ###########################\" , len(tl_img) , cnt)\n",
        "        # increase the class that have < MAX images \n",
        "        diff = MAX - len(tl_img)\n",
        "        sz = len(tl_img)\n",
        "        for i in range(0 , diff):\n",
        "            ind = np.random.randint(low=0 , high=sz)\n",
        "            timg = tl_img[ind]\n",
        "            # apply some agumentation \n",
        "            rot_img = combine_agumentation(timg[0])  # ***************************** will change the dimension a bit ************************\n",
        "            tl_img.append((rot_img , \"inc\"+timg[1]))   # was BUG \n",
        "            tl_label.append(label_dict[class_name])  # ***\n",
        "\n",
        "        # split into train , valid  10% validation \n",
        "        end = len(tl_img) - int(0.1 * len(tl_img))\n",
        "        index = np.random.permutation(len(tl_img))\n",
        "\n",
        "        print(\"length ###########################\" , len(tl_img))\n",
        "        # save into new directories \n",
        "\n",
        "        # save into train \n",
        "        for i in range(0 , end):\n",
        "          print(\"saving train\")\n",
        "          ind = index[i]\n",
        "          timg = tl_img[ind]\n",
        "          tmp_class_path =os.path.join(save_train_path , class_name) \n",
        "          tmp_img_path = os.path.join(tmp_class_path , timg[1])\n",
        "          cv2.imwrite(tmp_img_path , timg[0])\n",
        "        \n",
        "        # save into valid \n",
        "        for i in range(end , len(tl_img)):\n",
        "          print(\"saving valid\")\n",
        "          ind = index[i]\n",
        "          timg = tl_img[ind]\n",
        "          tmp_class_path =os.path.join(save_valid_path , class_name)\n",
        "          tmp_img_path = os.path.join(tmp_class_path , timg[1])\n",
        "          cv2.imwrite(tmp_img_path , timg[0])\n",
        "\n",
        "print(\"start\")\n",
        "build_Data_Set()\n",
        "print(\"end\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23MLk3YChNrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate train and validation data   csv files \n",
        "\n",
        "# labels as in kaggle but 0 - based \n",
        "label_dict = {'airport_inside': 0, 'bakery': 1, 'bedroom': 2, 'greenhouse': 3,\n",
        "              'gym': 4, 'kitchen': 5, 'operating_room': 6, 'poolinside': 7,\n",
        "              'restaurant': 8, 'toystore': 9}\n",
        "    \n",
        "def generate_csv_file(path):\n",
        "    class_file = listdir(path)\n",
        "    \n",
        "    paths = []\n",
        "    labels = []\n",
        "\n",
        "    for class_name in class_file:\n",
        "      class_path = os.path.join(path , class_name)\n",
        "      class_file = listdir(class_path)\n",
        "\n",
        "      for img_name  in class_file:\n",
        "          img_path = os.path.join(class_path , img_name)\n",
        "\n",
        "          # save the path and the id \n",
        "          #label_id = label_dict[class_name]  # 0 - based as kaggle \n",
        "          paths.append(img_path)\n",
        "          labels.append(class_name)\n",
        "    \n",
        "    paths , labels = shuffle(np.array(paths) , np.array(labels))\n",
        "    print(\"length os the whole train data is \" , len(paths) , len(labels))\n",
        "    save_to_csv(paths , labels , 'train.csv')\n",
        "\n",
        "def save_to_csv(image_path, labelid, name):\n",
        "    tmp_dict = {\"path\":image_path , \"label\":labelid}\n",
        "    Data = pd.DataFrame(tmp_dict)\n",
        "    Data.to_csv(name)\n",
        "    return Data\n",
        "\n",
        "print(\"start\")\n",
        "generate_csv_file(\"/content/my_train/train\")\n",
        "print(\"end\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6p_kjQVUc-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def VGG_16(lmda=0.0005 , drop=0.3):\n",
        "\n",
        "    # winit = RandomNormal(mean=0.0 , stddev=0.01)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # first block of conv layers\n",
        "    model.add(Conv2D(64 , (3 , 3) , padding='same' , activation='relu' , input_shape=(227 , 227 , 3) , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(64 , (3 , 3) , strides=(1 , 1) , padding='same'  , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # second block of conv layers\n",
        "    model.add(Conv2D(128 , (3 , 3) , padding='same' , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # third block of conv layers\n",
        "    model.add(Conv2D(256 , (3 , 3) , padding='same' , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(256 , (3 , 3) , padding='same' , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # forth block\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # fifth block\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(lmda)))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "    # flatten\n",
        "    model.add(Flatten())  # channel last\n",
        "    #model.add(Dropout(rate=drop))           # ************************************************************\n",
        "\n",
        "    # fully connected layers\n",
        "    model.add(Dense(4096 , activation='relu' , kernel_regularizer=l2(lmda)))\n",
        "    model.add(Dropout(rate=drop))\n",
        "\n",
        "    model.add(Dense(4096, activation='relu' , kernel_regularizer=l2(lmda)  ))\n",
        "    model.add(Dropout(rate=drop))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax',  kernel_regularizer=l2(lmda)  ))\n",
        "\n",
        "    return model\n",
        "\n",
        "def freeze_layers(model):\n",
        "    print(\"freze conv layers\")\n",
        "    index = [ 0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15]   #, 16]\n",
        "    for i in range(0 , len(index)):\n",
        "        model.layers[index[i]].trainable=False   # bug *****************************\n",
        "\n",
        "    #print(\"freze FC layers\")\n",
        "    #index = [19, 21, 23]\n",
        "    #for i in range(0, len(index)-1):\n",
        "      #model.layers[index[i]].trainable = False    # bug ********************\n",
        "      \n",
        "    return model\n",
        "\n",
        "# load trianable parameters \n",
        "\n",
        "def set_conv_weights(model, index , path=\"/content/drive/My\"+\" \"+\"Drive/vgg16_weights.npz\"):\n",
        "    print(\"initialize  some conv layers \")\n",
        "    W = np.load(path)\n",
        "    block = 1\n",
        "    layer = 1\n",
        "\n",
        "    for i in range(0 , len(index)):\n",
        "        # reset the pattern , by detecting\n",
        "        # the max pool layer and flatten layer\n",
        "        if i!=0 and index[i]-index[i-1]>1:\n",
        "            block += 1\n",
        "            layer = 1\n",
        "\n",
        "        weight = \"conv\" + str(block) + '_' + str(layer) + '_' + 'W'\n",
        "        bias = \"conv\" + str(block) + '_' + str(layer) + '_' + 'b'\n",
        "\n",
        "        # make sure that we are the right match\n",
        "        X , Y =model.layers[index[i]].get_weights()\n",
        "        X = X.shape\n",
        "        Y = Y.shape\n",
        "        XX = W[weight].shape\n",
        "        YY = W[bias].shape\n",
        "        #print(X , XX , Y , YY)\n",
        "        assert(X == XX and Y == YY)\n",
        "\n",
        "        #print(\"for debugining \" , index[i] , weight , bias)\n",
        "        model.layers[ index[i] ].set_weights([W[weight] , W[bias]])\n",
        "        layer +=1\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def set_fc_weights(model , index, path=\"/content/drive/My\"+\" \"+\"Drive/vgg16_weights.npz\"):\n",
        "    print(\" initialize some FC layers \")\n",
        "    W = np.load(path)\n",
        "\n",
        "    layer = 6\n",
        "    for i in range(0 , len(index)-1): # leave the output layer\n",
        "        model.layers[index[i]].set_weights([W[\"fc\"+str(layer)+\"_W\"] , W[\"fc\"+str(layer)+\"_b\"]])\n",
        "        layer += 1\n",
        "\n",
        "    return model\n",
        "\n",
        "def set_weights(model):\n",
        "    # I think we don't need to return the model back as we edit what in it not assign to it \n",
        "    print(\"in set weights\")\n",
        "    # conv layers\n",
        "    index = [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15 , 16]\n",
        "    model = set_conv_weights(model, index)\n",
        "\n",
        "    # fulle connected layers\n",
        "    index = [19, 21, 23]\n",
        "    model = set_fc_weights(model , index)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiXeodHaSihJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG-16   keras from scratch\n",
        "\n",
        "print(\"start\")\n",
        "Batch_Size = 256\n",
        "Learning_rate = 0.001\n",
        "model = VGG_16() \n",
        "model = freeze_layers(model)\n",
        "model = set_weights(model)\n",
        "\n",
        "sgd = SGD(lr=Learning_rate , momentum=0.9)\n",
        "# opt = Adam(lr=0.01)\n",
        "model.compile(optimizer=sgd , loss=\"categorical_crossentropy\" , metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "\n",
        "# callbacks \n",
        "best_val_acc = ModelCheckpoint('bestmodel.h5' , monitor='val_acc' , save_best_only=True , mode='max')\n",
        "\n",
        "\n",
        "\n",
        "# generators  Image Agumentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "                               data_format='channels_last')\n",
        "valid_datagen = ImageDataGenerator(\n",
        "                               data_format='channels_last')\n",
        "\n",
        "# Data generator \n",
        "train_generator = train_datagen.flow_from_directory(directory='/content/my_train/train',\n",
        "                                                    target_size=(227, 227),\n",
        "                                                    batch_size=Batch_Size,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    )\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory='/content/my_valid/valid',\n",
        "                                                    target_size=(227, 227),\n",
        "                                                    batch_size=Batch_Size,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    )\n",
        "\n",
        "\n",
        "# train the model \n",
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch = 5893 // Batch_Size,\n",
        "                    epochs=100 ,\n",
        "                    validation_data=valid_generator, \n",
        "                    callbacks=[best_val_acc], \n",
        "                    validation_steps = 1113 // Batch_Size)\n",
        "\n",
        "print(\"******** mapping *********\")\n",
        "\n",
        "print(train_generator.class_indices)\n",
        "\n",
        "# model.fit(x=X_train , y=Y_train , batch_size=256 , epochs=50 ,callbacks=[best_val_acc], validation_data=(X_valid , Y_valid))\n",
        "\n",
        "print(\"save weights\")\n",
        "model.save_weights('full_weights.h5')\n",
        "\n",
        "print(\"save model\")\n",
        "model.save('full_model.h5')\n",
        "print(\"end\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-eYSoKpudZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGThaI67jM5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm bestmodel.h5 \n",
        "!rm full_model.h5\n",
        "!rm full_weights.h5\n",
        "!rm adc.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sw6Ex6hqPXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict \n",
        "def get_5_portions(img , inputH=227 , inputW=227):\n",
        "    H , W , _ = img.shape\n",
        "\n",
        "    # first portion\n",
        "    img_l = []\n",
        "    img_l.append(img[0:227 , 0:227 , :])\n",
        "\n",
        "    # second portion\n",
        "    img_l.append(img[0:227 , W-228:W-1 , :])  # order of the second index matters !!!\n",
        "\n",
        "    # third portion\n",
        "    img_l.append(img[H-228:H-1 , 0:227 , :])\n",
        "\n",
        "    # 4th portion\n",
        "    img_l.append(img[H-228:H-1 , W-228:W-1 , :])\n",
        "\n",
        "    # get center portion\n",
        "    midH = H//2\n",
        "    midW = W//2\n",
        "\n",
        "    startH = midH - inputH//2\n",
        "    endH = midH + inputH//2 + (inputH%2)\n",
        "\n",
        "    startW = midW - inputW//2\n",
        "    endW = midW + inputW // 2 + (inputW % 2)\n",
        "    img_l.append(img[startH:endH , startW:endW , :])\n",
        "\n",
        "    # check\n",
        "    \"\"\"\n",
        "    index = 0\n",
        "    for timg in img_l:\n",
        "        H , W , C = timg.shape\n",
        "        # print(index)  # for debuging\n",
        "        assert(H==inputH and W==inputW and C==3)\n",
        "        index +=1\n",
        "    \"\"\"\n",
        "    return img_l\n",
        "\n",
        "def predict(X):\n",
        "    labels = model.predict(X)\n",
        "    labels = np.squeeze(np.argmax(labels , axis=1))\n",
        "\n",
        "    labels = np.bincount(labels)\n",
        "    labels= np.argmax(labels)\n",
        "    return labels\n",
        "\n",
        "def test(path):\n",
        "    img_name  =  []\n",
        "    img_label =  []\n",
        "\n",
        "    mean = np.load('DS_local_mean.npy')\n",
        "    mean = mean.reshape(1 , 1 , 3)\n",
        "\n",
        "    file = listdir(path)\n",
        "    for name in file:\n",
        "        final_path = path + \"/\" + name #os.path.join(path , name)\n",
        "        img = cv2.imread(final_path , -1)\n",
        "\n",
        "        ###################################################################################\n",
        "\n",
        "        # bad image\n",
        "        if name=='1412_mb_file_0a8c5_gif.jpg':   # gif image\n",
        "            print(\"bad image \")\n",
        "            img_name.append(name)\n",
        "            img_label.append(rlabel_dict['greenhouse'])\n",
        "            continue\n",
        "        if name==\"operating_room_07_06_altavista.jpg\":  # gray scale img and my model take only RGB\n",
        "            print(\"bad image \")\n",
        "            img_name.append(name)\n",
        "            img_label.append(rlabel_dict['operating_room'])\n",
        "            continue\n",
        "\n",
        "        ####################################################################################\n",
        "\n",
        "        # put the image in the same conditions of training\n",
        "        print(name)\n",
        "        # RGB\n",
        "        img = img[: , : , (2 , 1 , 0)]\n",
        "\n",
        "        # resize into 256 * 256\n",
        "        img = preprocessing(img)\n",
        "\n",
        "        # subtract the mean\n",
        "        img = img - mean\n",
        "\n",
        "        # normalize the image\n",
        "        img = normalize_min_max(img)\n",
        "\n",
        "        # this procedure is from alexnet - image net paper\n",
        "        # generate all the agumented imgs and vote for label\n",
        "        img_l = []\n",
        "        img_l = get_5_portions(img)\n",
        "        #get the flips of each image\n",
        "        sz = len(img_l)\n",
        "        for i in range(0 , sz):\n",
        "            fimg= horizontal_reflication_img(img_l[i])\n",
        "            img_l.append(fimg)\n",
        "        img_l = np.array(img_l).reshape(-1 , 227 , 227 , 3)  # to be predicted\n",
        "        label = predict(img_l)\n",
        "\n",
        "        # build the file\n",
        "        img_name.append(name)\n",
        "        img_label.append(label+1)  # stupid file\n",
        "    return img_name , img_label  # to be saved into csv file\n",
        "\n",
        "def save_to_csv_file(names , labels):\n",
        "  Data = {\"id\":names , \"lable\":labels}\n",
        "  Data = pd.DataFrame(Data)\n",
        "  Data.to_csv(\"mysubmit.csv\")\n",
        "  return Data\n",
        "\n",
        "\n",
        "print(\"start\")\n",
        "\n",
        "model = load_model(\"/content/full_model.h5\")#\"/content/drive/My\"+\" \"+\"Drive/model.h5\") # this is model with only output trained\n",
        "rlabel_dict = read_from_dics('rlabel_dict')\n",
        "\n",
        "print(rlabel_dict)\n",
        "\n",
        "names , labels = test('/content/test/test')\n",
        "print(\"\\n\\n\")\n",
        "print(names)\n",
        "print(labels)\n",
        "\n",
        "print(\"end\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0YdtssUQf9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(\"/content/train/train/\"))\n",
        "colab_l_i = read_from_dics(\"label_dict\")\n",
        "print(colab_l_i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFmh7oSmpSjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount google drive with colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XdtkdEbnz5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doawnload model wights \n",
        "from google.colab import files\n",
        "files.download(\"checkpoint\")\n",
        "files.download(\"model.tfl.meta\")\n",
        "files.download(\"model.tfl.index\")\n",
        "files.download(\"model.tfl.data-00000-of-00001\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMZyWSF73nnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"start\")\n",
        "# load data\n",
        "X = np.load('/content/X.npy')\n",
        "Y = np.load('/content/Y.npy')\n",
        "sess = tf.Session()\n",
        "Y = sess.run(tf.one_hot(Y , depth=10))\n",
        "sess.close()\n",
        "Y = np.squeeze(Y)\n",
        "\n",
        "model = load_model(\"/content/drive/My\"+\" \"+\"Drive/model.h5\")\n",
        "#print(model.summary())\n",
        "pred = model.predict(X)\n",
        "print(model.evaluate(X , Y))\n",
        "\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIrRnhQhyK15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm X.npy\n",
        "!rm Y.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xjirb6Uz6gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# play around a little \n",
        "X = np.load(\"X.npy\")\n",
        "img = X[55]\n",
        "print(img)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl8925tH2E_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg6sv1OWWeK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 2. Save Keras Model or weights on google drive\n",
        "\n",
        "# create on Colab directory\n",
        "\n",
        "model_file = drive.CreateFile({'title' : 'bestmodel94_delaug_no_norm.h5'})\n",
        "model_file.SetContentFile('bestmodel94_delaug_no_norm.h5')\n",
        "model_file.Upload()\n",
        "\n",
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RpHafJVwhy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}